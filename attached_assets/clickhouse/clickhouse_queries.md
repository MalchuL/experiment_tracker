# ClickHouse Queries –¥–ª—è Research Platform

## –ß–∞—Å—Ç—å 1: –î–∏–∞–≥—Ä–∞–º–º—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

### Data Flow –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫

```
SDK (Python) –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ
        ‚Üì
[metric_name="loss", value=0.42, step=10]
        ‚Üì
HTTP POST /api/v1/metrics/batch (–±–∞—Ç—á –∏–∑ 100 –º–µ—Ç—Ä–∏–∫)
        ‚Üì
FastAPI Endpoint (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ —á–µ—Ä–µ–∑ team_id)
        ‚Üì
ClickHouseClient.insert_metrics_batch()
        ‚Üì
INSERT INTO metrics (ClickHouse)
        ‚Üì
Celery Task: process_metric_stream()
  ‚îú‚îÄ –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≥–∏–ø–æ—Ç–µ–∑—ã, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫—É
  ‚îú‚îÄ –í—ã—á–∏—Å–ª–∏—Ç—å Evidence Units
  ‚îú‚îÄ INSERT INTO evidence_metrics
  ‚îî‚îÄ UPDATE hypothesis.status –≤ PostgreSQL
```

### Evidence Model Flow

```
Hypothesis: "AdamW —Å lr=1e-4 –±—ã—Å—Ç—Ä–µ–µ —Å—Ö–æ–¥–∏—Ç—Å—è"
    ‚Üì
target_metrics: ["loss", "accuracy"]
baseline: "exp-0-baseline"
    ‚Üì
[Exp-1: loss=0.42, acc=0.95]
[Exp-2: loss=0.38, acc=0.96]
[Exp-3: loss=0.45, acc=0.93]
    ‚Üì
Evidence Unit –¥–ª—è –∫–∞–∂–¥–æ–≥–æ exp:
    Exp-1: delta_loss = -0.08, delta_acc = +0.05, confidence=0.8
    Exp-2: delta_loss = -0.04, delta_acc = +0.06, confidence=0.85
    Exp-3: delta_loss = +0.03, delta_acc = -0.02, confidence=0.7
    ‚Üì
Hypothesis Evidence = SUM(confidence * normalized_delta)
    = 0.8*(-0.08) + 0.85*(-0.04) + 0.7*(0.03) + ...
    = -0.064 - 0.034 + 0.021 = -0.077
    ‚Üì
Status = "Testing" (–º–µ–∂–¥—É -0.5 –∏ 0.5)
```

---

## –ß–∞—Å—Ç—å 2: SQL Queries –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

### 1. –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

```sql
-- –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–Ω–∞—á–µ–Ω–∏–π –º–µ—Ç—Ä–∏–∫–∏ "loss" –¥–ª—è exp-123
SELECT
    timestamp,
    step,
    metric_value as loss
FROM metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND experiment_id = '550e8400-e29b-41d4-a716-446655440123'
  AND metric_name = 'loss'
ORDER BY timestamp ASC
LIMIT 100;
```

### 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç—Ä—ë—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```sql
-- –§–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è 3 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
SELECT
    experiment_id,
    metric_name,
    argMax(metric_value, timestamp) as final_value
FROM metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND experiment_id IN (
      '550e8400-e29b-41d4-a716-446655440111',
      '550e8400-e29b-41d4-a716-446655440112',
      '550e8400-e29b-41d4-a716-446655440113'
  )
GROUP BY experiment_id, metric_name
ORDER BY experiment_id, metric_name;
```

**Result (pivot –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞):**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ experiment_id    ‚îÇ metric_name   ‚îÇ final_value‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ exp-111          ‚îÇ loss          ‚îÇ 0.42       ‚îÇ
‚îÇ exp-111          ‚îÇ accuracy      ‚îÇ 0.95       ‚îÇ
‚îÇ exp-112          ‚îÇ loss          ‚îÇ 0.38       ‚îÇ
‚îÇ exp-112          ‚îÇ accuracy      ‚îÇ 0.96       ‚îÇ
‚îÇ exp-113          ‚îÇ loss          ‚îÇ 0.45       ‚îÇ
‚îÇ exp-113          ‚îÇ accuracy      ‚îÇ 0.93       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3. –¢—Ä–µ–Ω–¥—ã: —É–ª—É—á—à–µ–Ω–∏–µ/—É—Ö—É–¥—à–µ–Ω–∏–µ

```sql
-- –ö–∞–∫ –º–µ–Ω—è–ª–∏—Å—å –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É
-- (DAG –ø–æ—Ä—è–¥–æ–∫: exp-0 ‚Üí exp-1 ‚Üí exp-2 ‚Üí exp-3)
WITH metric_timeline AS (
    SELECT
        experiment_id,
        metric_name,
        argMax(metric_value, timestamp) as final_value,
        COUNT(*) as point_count
    FROM metrics
    WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
      AND project_id = '550e8400-e29b-41d4-a716-446655440002'
    GROUP BY experiment_id, metric_name
)
SELECT
    metric_name,
    experiment_id,
    final_value,
    LAG(final_value) OVER (
        PARTITION BY metric_name 
        ORDER BY experiment_id
    ) as prev_value,
    final_value - LAG(final_value) OVER (
        PARTITION BY metric_name 
        ORDER BY experiment_id
    ) as delta
FROM metric_timeline
ORDER BY metric_name, experiment_id;
```

### 4. –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–µ

```sql
-- –ù–∞–π—Ç–∏ experiment —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –ø–æ—Ç–µ—Ä–µ–π (MINIMIZE)
SELECT
    experiment_id,
    metric_name,
    MIN(metric_value) as min_loss,
    argMinIf(timestamp, metric_value, timestamp > now() - INTERVAL 24 HOUR) as time_achieved
FROM metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND metric_name = 'loss'
GROUP BY experiment_id, metric_name
ORDER BY min_loss ASC
LIMIT 1;
```

### 5. Evidence –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã

```sql
-- –í—Å–µ Evidence Units –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã h-123
SELECT
    experiment_id,
    metric_name,
    baseline_value,
    experiment_value,
    delta,
    IF(direction = 0, 'minimize', 'maximize') as direction,
    confidence_score,
    timestamp
FROM evidence_metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND hypothesis_id = '550e8400-e29b-41d4-a716-446655440321'
ORDER BY timestamp DESC;
```

**Result:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ experiment   ‚îÇ metric      ‚îÇbaseline‚îÇexperiment   ‚îÇ delta  ‚îÇ dir  ‚îÇconfidence‚îÇtimestamp ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ exp-1        ‚îÇ loss        ‚îÇ 0.50   ‚îÇ 0.42        ‚îÇ-0.08   ‚îÇmin   ‚îÇ 0.80     ‚îÇ 2024-... ‚îÇ
‚îÇ exp-1        ‚îÇ accuracy    ‚îÇ 0.90   ‚îÇ 0.95        ‚îÇ+0.05   ‚îÇmax   ‚îÇ 0.85     ‚îÇ 2024-... ‚îÇ
‚îÇ exp-2        ‚îÇ loss        ‚îÇ 0.50   ‚îÇ 0.38        ‚îÇ-0.12   ‚îÇmin   ‚îÇ 0.75     ‚îÇ 2024-... ‚îÇ
‚îÇ exp-2        ‚îÇ accuracy    ‚îÇ 0.90   ‚îÇ 0.96        ‚îÇ+0.06   ‚îÇmax   ‚îÇ 0.82     ‚îÇ 2024-... ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã

```sql
-- –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ Evidence –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã
SELECT
    hypothesis_id,
    COUNT(*) as unit_count,
    SUM(confidence_score * delta) as total_evidence,
    AVG(confidence_score) as avg_confidence,
    MIN(experiment_value) as best_value,
    MAX(experiment_value) as worst_value
FROM evidence_metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND hypothesis_id = '550e8400-e29b-41d4-a716-446655440321'
GROUP BY hypothesis_id;
```

### 7. –°–∞–º—ã–µ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

```sql
-- –ú–µ—Ç—Ä–∏–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π (—Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è)
SELECT
    experiment_id,
    metric_name,
    COUNT(*) as points,
    AVG(metric_value) as avg_value,
    MIN(metric_value) as min_value,
    MAX(metric_value) as max_value,
    MAX(metric_value) - MIN(metric_value) as range,
    stddevPopStable(metric_value) as stddev
FROM metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
  AND timestamp > now() - INTERVAL 7 DAY
GROUP BY experiment_id, metric_name
HAVING stddev > 0.1
ORDER BY stddev DESC;
```

### 8. –°–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏

```sql
-- –ù–∞ –∫–∞–∫–æ–º —à–∞–≥–µ –º–µ—Ç—Ä–∏–∫–∞ –¥–æ—Å—Ç–∏–≥–ª–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
WITH metric_steps AS (
    SELECT
        experiment_id,
        step,
        metric_value,
        LAG(metric_value) OVER (
            PARTITION BY experiment_id 
            ORDER BY step
        ) as prev_value
    FROM metrics
    WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
      AND project_id = '550e8400-e29b-41d4-a716-446655440002'
      AND metric_name = 'loss'
)
SELECT
    experiment_id,
    MIN(step) as converged_at_step,
    COUNT(*) as total_steps
FROM metric_steps
WHERE metric_value < 0.4  -- Target value
GROUP BY experiment_id;
```

### 9. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –º–µ—Ç—Ä–∏–∫ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```sql
-- –†–∞–∑–¥–µ–ª–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ –≥—Ä—É–ø–ø—ã (batch size: –±–æ–ª—å—à–æ–π vs –º–∞–ª–µ–Ω—å–∫–∏–π)
-- –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
SELECT
    CASE 
        WHEN experiment_id LIKE 'exp-batch-large-%' THEN 'Large Batch'
        WHEN experiment_id LIKE 'exp-batch-small-%' THEN 'Small Batch'
        ELSE 'Other'
    END as group_name,
    metric_name,
    COUNT(*) as samples,
    AVG(metric_value) as mean,
    quantile(0.5)(metric_value) as median,
    quantile(0.25)(metric_value) as q25,
    quantile(0.75)(metric_value) as q75,
    stddevPopStable(metric_value) as stddev
FROM metrics
WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
  AND project_id = '550e8400-e29b-41d4-a716-446655440002'
GROUP BY group_name, metric_name
ORDER BY group_name, metric_name;
```

### 10. –ú–µ—Ç—Ä–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–∫–∞—á—É—Ç (—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ)

```sql
-- –ù–∞–π—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –≤–∞—Ä–∏–∞—Ü–∏–∏ < 0.1 (—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ)
WITH metric_stats AS (
    SELECT
        experiment_id,
        metric_name,
        AVG(metric_value) as mean_value,
        stddevPopStable(metric_value) as std_value,
        stddevPopStable(metric_value) / AVG(metric_value) as cv
    FROM metrics
    WHERE team_id = '550e8400-e29b-41d4-a716-446655440001'
      AND project_id = '550e8400-e29b-41d4-a716-446655440002'
      AND timestamp > now() - INTERVAL 1 DAY
    GROUP BY experiment_id, metric_name
)
SELECT *
FROM metric_stats
WHERE cv < 0.1
ORDER BY experiment_id, metric_name;
```

---

## –ß–∞—Å—Ç—å 3: Python –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

### –ò—Å–ø–æ–ª—å–∑—É—è httpx –¥–ª—è API calls

```python
# examples/analysis_client.py

import httpx
import pandas as pd
from typing import List, Dict
from uuid import UUID

class ResearchAnalysisClient:
    def __init__(self, base_url: str, token: str):
        self.base_url = base_url
        self.token = token
        self.headers = {"Authorization": f"Bearer {token}"}
    
    async def get_experiment_comparison(
        self,
        project_id: UUID,
        experiment_ids: List[UUID],
    ) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤ –≤–∏–¥–µ DataFrame"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/api/v1/metrics/compare",
                params={
                    "project_id": project_id,
                    "experiment_ids": [str(e) for e in experiment_ids],
                },
                headers=self.headers,
            )
            response.raise_for_status()
        
        data = response.json()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ DataFrame –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        rows = []
        for exp_id, metrics in data['experiments'].items():
            for metric_name, values in metrics.items():
                rows.append({
                    'experiment': exp_id,
                    'metric': metric_name,
                    'last': values['last'],
                })
        
        df = pd.DataFrame(rows)
        df_pivot = df.pivot(index='metric', columns='experiment', values='last')
        
        return df_pivot
    
    async def analyze_hypothesis(
        self,
        project_id: UUID,
        hypothesis_id: UUID,
    ) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥–∏–ø–æ—Ç–µ–∑—ã"""
        
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.base_url}/api/v1/hypotheses/{project_id}/{hypothesis_id}/evidence",
                headers=self.headers,
            )
            response.raise_for_status()
        
        data = response.json()
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        evidence_units = data['evidence_units']
        df = pd.DataFrame(evidence_units)
        
        return {
            'status': data['status'],
            'total_evidence': data['total_evidence'],
            'unit_count': len(evidence_units),
            'avg_confidence': df['confidence_score'].mean(),
            'evidence_by_metric': df.groupby('metric_name')['delta'].mean().to_dict(),
        }

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
async def main():
    client = ResearchAnalysisClient(
        base_url="http://localhost:8000",
        token="your-token",
    )
    
    # –°—Ä–∞–≤–Ω–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    df = await client.get_experiment_comparison(
        project_id=UUID("550e8400-e29b-41d4-a716-446655440002"),
        experiment_ids=[
            UUID("550e8400-e29b-41d4-a716-446655440111"),
            UUID("550e8400-e29b-41d4-a716-446655440112"),
            UUID("550e8400-e29b-41d4-a716-446655440113"),
        ],
    )
    
    print("Comparison Results:")
    print(df)
    print("\nImprovement over baseline (exp-111):")
    baseline = df['550e8400-e29b-41d4-a716-446655440111']
    for col in df.columns[1:]:
        improvement = (df[col] - baseline) / baseline * 100
        print(f"\n{col}:")
        print(improvement)
    
    # –ê–Ω–∞–ª–∏–∑ –≥–∏–ø–æ—Ç–µ–∑—ã
    hyp_analysis = await client.analyze_hypothesis(
        project_id=UUID("550e8400-e29b-41d4-a716-446655440002"),
        hypothesis_id=UUID("550e8400-e29b-41d4-a716-446655440321"),
    )
    
    print(f"\nHypothesis Status: {hyp_analysis['status']}")
    print(f"Total Evidence: {hyp_analysis['total_evidence']:.3f}")
    print(f"Units: {hyp_analysis['unit_count']}")
    print(f"Avg Confidence: {hyp_analysis['avg_confidence']:.2f}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

### Plotly –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è

```python
# examples/visualize_metrics.py

import plotly.graph_objects as go
import plotly.express as px
from app.core.dependencies import get_clickhouse_client
from uuid import UUID

def plot_metric_timeseries(
    team_id: str,
    project_id: str,
    experiment_id: str,
    metric_name: str,
):
    """–í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –º–µ—Ç—Ä–∏–∫–∏"""
    
    ch = get_clickhouse_client()
    
    points = ch.get_metric_timeseries(
        team_id=team_id,
        project_id=project_id,
        experiment_id=experiment_id,
        metric_name=metric_name,
    )
    
    df = pd.DataFrame([
        {
            'timestamp': p['timestamp'],
            'step': p['step'],
            'value': p['value'],
        }
        for p in points
    ])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=df['step'],
        y=df['value'],
        mode='lines+markers',
        name=metric_name,
        line=dict(width=2),
    ))
    
    fig.update_layout(
        title=f"{metric_name} –¥–ª—è {experiment_id}",
        xaxis_title="Step",
        yaxis_title="Value",
        hovermode='x unified',
        template='plotly_white',
    )
    
    return fig

def plot_experiment_comparison(
    team_id: str,
    project_id: str,
    experiment_ids: List[str],
    metric_names: List[str],
):
    """–°—Ä–∞–≤–Ω–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏ (bar chart)"""
    
    ch = get_clickhouse_client()
    
    comparison = ch.compare_experiments(
        team_id=team_id,
        project_id=project_id,
        experiment_ids=experiment_ids,
        metric_names=metric_names,
    )
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–ª—è plotly
    data = []
    for exp_id in experiment_ids:
        for metric_name in metric_names:
            if metric_name in comparison[exp_id]:
                value = comparison[exp_id][metric_name]['last']
                data.append({
                    'experiment': exp_id[:8],  # truncate for display
                    'metric': metric_name,
                    'value': value,
                })
    
    df = pd.DataFrame(data)
    
    fig = px.bar(
        df,
        x='metric',
        y='value',
        color='experiment',
        barmode='group',
        title="Metric Comparison",
        template='plotly_white',
    )
    
    return fig

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
fig1 = plot_metric_timeseries(
    team_id="team-123",
    project_id="proj-456",
    experiment_id="exp-789",
    metric_name="loss",
)
fig1.show()

fig2 = plot_experiment_comparison(
    team_id="team-123",
    project_id="proj-456",
    experiment_ids=["exp-111", "exp-222", "exp-333"],
    metric_names=["loss", "accuracy"],
)
fig2.show()
```

---

## –ß–∞—Å—Ç—å 4: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ hints

### Query Planning

–ü–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Å–ª–æ–∂–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `EXPLAIN`:

```sql
EXPLAIN
SELECT
    experiment_id,
    metric_name,
    COUNT(*) as points
FROM metrics
WHERE team_id = '...'
  AND project_id = '...'
  AND metric_name = 'loss'
GROUP BY experiment_id, metric_name;
```

ClickHouse –ø–æ–∫–∞–∂–µ—Ç –ø–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫—É.

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å FINAL –¥–ª—è ReplacingMergeTree

```sql
-- –ï—Å–ª–∏ –Ω—É–∂–Ω—ã –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ—Å–ª–µ OPTIMIZE)
SELECT *
FROM metrics
FINAL
WHERE team_id = '...'
ORDER BY timestamp DESC
LIMIT 10;
```

### Batch —Ä–∞–∑–º–µ—Ä—ã

- –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch = 10-100K —Å—Ç—Ä–æ–∫ –∑–∞ —Ä–∞–∑
- –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ (~10) ‚Üí overhead
- –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ (>1M) ‚Üí OOM –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ

---

## –†–µ–∑—é–º–µ: –≥–æ—Ç–æ–≤—ã–µ SQL —à–∞–±–ª–æ–Ω—ã

- ‚úÖ –ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –º–µ—Ç—Ä–∏–∫–∏
- ‚úÖ –°—Ä–∞–≤–Ω–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- ‚úÖ –í—ã—á–∏—Å–ª–∏—Ç—å Evidence Units
- ‚úÖ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≥–∏–ø–æ—Ç–µ–∑—ã
- ‚úÖ –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
- ‚úÖ –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫

–í—Å—ë –≥–æ—Ç–æ–≤–æ –¥–ª—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã! üéâ
